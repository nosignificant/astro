---
date: 2025-05-30
tags:
  - SOFTWARE
---

# 0310

컴퓨터로 이미지 표현하기
viewer, object, light, attributes,

### openGL rendering Pipeline

- 버텍스 입력(3디 모델링이겠죠) -여기서부터 연산과정-
- 버텍스 프로세서? - 카메라 기준 버텍스 위치 계산
- 클리퍼앤 프리미티브어셈블러 - 보이는 기준에서 삼각형, 사각형 그림
- 래스터화 - 점들로이루어진 추상적인 사각형을 프래그먼트로 바꿈
- 프래그먼트 프로세서 - 만들어진 픽셀단위 계산, 색으로 그림
  이러고 픽셀으로 나옴
  네? 그래서 픽셀이랑 프래그먼트랑 나눈 이유가 뭐라고요?

근데 1번하고 2번..이러면 ㅈㄴ오래걸리겠죠 병렬으로 해야겠죠

지난번에 했죠? fixed rendering pipeline & programmable
이 두가지는 둘다 저 4번의 과정이 같음
근데 각각의 유닛이 하드웨어로 묶여있으면 fixed
근데 이 과정에서 쉐이더를 직접짜서? 쉐이더라는 언어로 짜서 편집할 수 있으면 programmable
하드웨어에 안 묶여있고 그 과정을 어플리캐이션을 통해 코드로 올릴 수 있으면..?

처음부터 버텍스를 많이 보내면 되지 않나요? : 컴퓨터가 GPU로 정보를 보내는데 시간이 걸림, 그리고GPU내의메모리에서 계산해서 화면에 보냄

먼말인지모르게떠염

### 보는걸이해하기

클리핑 영역을 어떻게 정하나

---

# 0317

### camera specification

- perspective/orthographic projection
- image clipping : 왼오상하 + 앞뒤
  (ppt자료의) 사각뿔 형태 안에 들어가는 폴리곤만 렌더링
- extrinsic parameters: 카메라가 세상에 어떻게 놓여야 상이 결정되나
  카메라 바깥의 요인(위치,각도) - transformation 정보
  걍 3d 수업을 이론으로 배우고 있는데 정말 재미없군 프로그램으로 만지면서하는게 더 재미있지 않을까요
  위치 전달하긴 쉬운데 xyz회전 각도를 90도를 유지시켜야 깨지지 않는데 이걸 유지시키는 게 어려운 문제

```JavaScript
voidgluLookAt(GLdouble 눈 위치, 바라봐야 하는 곳, up이라는 방향)
```

눈 위치 - 바라보는 곳을 연결하면 z의방향 - 벡터가 나오겠죠
up 이라는 방향을 줘서 고개의 각도를 결정 - 이걸로 모든 xyz회전축을 90도로 맞추려고 함
평면을 만들고 거기에 법선 90도를 찍는건 쉬우니까 그렇게 하려고하는데 이때 쓰이는 게 up
up이있으면 바라보고 있는 곳이랑 연결되어서 평면을 만들 수 있음
그래서 이 up과 바라보고 있는 곳으로 만들어진 평면에 법선 90도를 그리고, 이 90도로 만들어진 방향으로 새롭게 위쪽 up을만듦
이 미친 것… pivot이1이 아닐 수도 있으니 1이 되도록 만들어주기도 해야함
이걸 다 계산하는 거였다고? ㅋㅋ

- 오른손 좌표계…
  x y 를쥐면 따봉의 방향이 나오는데 이 방향이 +z라고 하네요
  왼쪽으로가면 - 고 오른쪽으로가면 + 인걸 딩초때부터 합의 했죠
  우리 함수 배울때 xy의방향을 상상하고 이 xy를 쥐면 z는평면 밖으로 나오는 축이 + 겠네요
  오…근데 그림판은 왼쪽 위가 0,0이네요 그림판은 openCV인데 얘는 아래쪽이 y+ 방향이라 페이지 안쪽으로 뚫고 들어가야 z+라고하네요 오 ㅋㅋ 이거 유니티에서 왜z값 증가하면 밑으로가는지 이해함
- intrinsic parameters: focal length - field of view 를 조절함으로써
  줌인 줌아웃
  필름을 렌즈쪽에 붙이면 줌아웃 반대로하면 줌인
  완전 좁은 영역을 보려고하면 줌인인거겠죠
  openGL은위아래각만 사용한다고 하네요 (좌우비율은 계산할 수 있으니까)
  카메라에 담아내는 영역을 조절하는…? 그런 거라고 하네요

```JavaScript
void gluPerspective(GLdouble 앵글, 높이/너비 비율, 카메라로부터 거리, 화폭까지 거리)
```

이거 말로만 이해하지 말고 그림이랑 같이 이해하는 게 더 이해하기 좋을 것 같네요
clipping 뭔 말인지…
저희가 쌩으로 다 짜라고요?

- viewport
  렌더링된것을 화면에 보여주는 영역
- Aspect ratio
  너비 높이의 화면 비율

openGL 데모를한번 해보시길

### Modeling of Synthetic Object

어떤방식으로 데이터가 저장이 될까

- 정점에 위치/노말/색상과 같은…정보, 면에는…뭐야?
  윽… 잠온다

어떤 정보가 어떻게 저장되어있는 걸까?

- 각 정점에 연결된 점 xyz위치값 4바이트씩 할당돼서 저장됨
  아무튼 ppt에있는 자료보면 점이 저장되는 순서가 있음 함 봐보셈

일단 점에대한 정보 쭉 쓰고 - 삼각형에 대한 정보는 이점들 방문하면 알 수 잇따 하는 정보를 주는거(4각형도 마찬가지

이거 정점들 연결되는거 obsidian graph view 같네

- 점을 어디로 보내나?: vertex array / vertex buffer objects\_
  object 하면gpu를쓰는거
  문제: c랑 python이 시스템 메모리에만 관여할 수 있음 - 이걸 해결 하기 위한게 shader
- 그래서 어떻게 메모리를 보내야 할까?

1. vertex Array : 메모리에서 그려달라고 모든 정보를 던짐, 점 300개를 넘겨주면 삼각형 100개를 그리겠죠

   배열을 만들고(gEnableVertexAttribArray) / 데이터로 삼각형을 만들고?(gVertexAttribPointer()) / 렌더 (gDrawArray)

   draw call 할때마다호출함

모든 정보는 cpu가접근할 수 있는 위치에 있어요 그래서 gpu님은렌더링을 할 때마다cpu에접근을해야돼요
배열의…이름은 배열의 위치인거. 기억…나시죠? ㄷㄷㅋㅋ
gpu쪽메모리도 있다… 2. vertex/index buffer objects

    버퍼오브젝트를 만드는 거래요 근데 교수님 너무잠와욧

    만들고 연결되는 정보 묶음

    request늖 위에서 묶었던 걸 확인하는듯?

    enable하고…또 연결된 정보 확인시키고…. 드디어 렌더…. 확인을 몇번이나 하는거냐…

cpu에있는메모리잡는 건 아무것도아닌거얔ㅋ이라네요 하하

---

# 0324

지난번에 했던 내용~ 대부분의 정보를 버텍스에 넣어둔다~

### vertexArray : 매번데이터 넘겨주는 방식

soup 방식/ vertex list랑 triangle은각각 다른 ㅅ방식으로 함수 콜해야함 - 이게 drawArray , drawElements 함수

### vertexBufferObject: 넘겨준데이터 재활용

1. 받을 준비하셈 간다
2. zenBuffer : 공책 n권 만들어라
3. glBindBuffer(2,??) -몇번 공책에 적으라고 알려주는 거 / 앞으로 내가 보내는건 말 안해도 3번 공책이야  
   ??에는 뭐가 들어가야할까여? 배열의 위치를 넣어야하기땜에 배열의 이름또는 시작되는 위치를 넘겨주면됩니다 미친..ㅋㅋ c++열심히 안한자의 최후
4. bufferData 만들기 - call 하면 똑같은 데이터가 gpu에생긴다?
5. 다른 스케치북에 그릴 거라고 정보를 끊거나 말거나 하는 코드도 있음
   얘도 마찬가지로 soup / vertex list + polygon이있음

여기까지의 과정이 cpu>> gpu의과정
그래서 어떻게 그릴 것인가… 6. 버텍스의 속성이 있는 곳을 알려줘 - 근데 GPU에있는 걸로 알아서 그려(cpu에 있는 메모리가 아니라서 위치를 알려줄 수가 없음) 7. 그려

근데 움직이려면 계속 화면을 다르게 그려야하는 거잖아
어떡할래? 3. 업데이트되는 코드를 짜서 GPU한테줌 : shader - GPU가 돌아가야하는 로직을 프로그래머가 짜서 주는 거 4. 와와아아아,, 와와와아아와와와와와와와!!!

### vertex Array방식

1. enable Array : 받을 준비하삼 - 하고 다 복사해서 존나 넣어줌 -
2. attribPointer : 하고 위치도 넣어줌
3. 그려

## transformation

카메라와 물체의 위치-상관관계 계산하기
3차원정보 표기를 위해서 4개의 정보가 필요하다네요
정보가 위치,숫자면 4개의 정보중 마지막 수를 1 - 벡터면 0으로

왜 이렇게 하냐?
30,20 좌표에 있다 쳐
원점과 30,20에 이어지는 선은 모두 같은 의미를 가짐 - homogeneous coordinate (동차좌표)
얘가 커져도?..
그래서 … 숫자면 1을 준다고…
흡…그래서 왜 1을 썼는지 자서 못들었어

### Affine space

점을 나타내는 좌표 3,2 일떄 벡터를 나타내는 것도 3,2로 똑같이 씀- 근데 원래 이렇게 하면 안됔
점이랑 벡터는 다르죠 / 스칼라 벡터 포인터를 하나로 묶은게 affine space
위치랑 뭐시기를 구별지어서 보여주려고

물리적으로 의미있는 연산체계 만들기
벡터+벡터(힘+힘) 스칼라+벡터 곱셈… 얘네는 원래 있는 애들이고
위치랑 벡터를 더하는 개념을 만듦

벡터의 문제… 시작하는 점, 위치에 대한 개념이 존재하지 않음 (힘이란 건 똑같은 작용을 일으키니까 위치가 필요가 없음)
점 - 점을 하면 벡터라는 개념을 만들 수 있대
근데 위치 + 변위를 더하면 위치가 나온다 - 부산에 400km이동을 하면 서울이나오는거처럼
이 논리를 다 숫자로 바꿔야됨 시발

### homogeneous Coordinates

n차원의 정보를 표기하기 위해서 n+1의정보가 필요
위치는 이제 3,2,1으로표현, 벡터는 3,2,0으로표현하기로 한거임
위치를 3배한다는 개념은 통용되지 않음

행렬은 함수? - 그래서 transformation은4x4 함수
openGL 은column단위로 저장 / 팔또치가 뭔데요 ( 얘는 row 단위라는데)
이게 함수라고…..?
행렬이 함수한 게 뭔소리지...?

## linear transformations

non linear은 그냥 직선이동의 모임

### translation

행렬을 함수로 바꿈
세로로 있다고 치고 마음의 눈으로 보삼
x' = Tx

x' = 13 7 -2 1
1 0 0 0
0 1 0 0
0 0 1 0
T = 10 5 -1 1
x = 3 2 -1 1
여기서 t는 함수
라는데 뭔말?
이걸 2x2라는 행렬로 해석한다고?

t(dx, dy, dz) 만큼 움직여라

[cos - sin]뭐 이렇게 생겼는데
[sin - cos]
함수를 행렬로 짤수있다는게 뭔뜻인데...

각 숫자보단 열이 어떤 의미를 갖는지

확대, 회전은 원점을 통해서 - 원점은 회전하지 않음

# 0331

합성변형

함수는 뒤에있는 거부터 적용
물체중심이동하고싶을때
물체를 원점에 갖다놓고(거리만큼 빼서)
회전시킨뒤
다시 제자리에 갖다놓음

### instancing

모델정보는 1개 주고, 그 모델의 복사본을 데려올 때 그 버텍스를 각각 받는 게 아니고 하나만 갖고 같은 형태의 다른 오브젝트에도 적용
개체마다 다른 변환 적용

### 태양계 표현

### coordinate system

젤 끝의 수가 0이면 처름 시작 좌표 자체가 의미가 없음

- orthonormal frames

### gluLookAt은 어떻게 구성되어있는가?

회전과 이동
역행렬을 취하면... 합성함수에서 자리바뀌는거처럼 자리가바뀜?

#### 역행렬 구하기

이동: dx, dy, dz 이거에 -하면 됨
회전: transpose 하면 된다네요 (왜그러냐면 그냥 두개를 곱해보라는데)

헉 근데 역행렬을 왜 쓰는거지
아 원래 있던걸 위치로옮겨놓고 회전시키는 거에 반대를 해야하니까?
오 왜 역행렬해야하는지는 나중에 말해준대 ㅋㅋ

아 역행렬돼서 원래 회전-이동의 행렬이랑 안맞으니까 이상하게 여긴대

## Vertex processor

정점들이 받은 거 만으론 안되고 카메라가 바라보고 있는 시점에서 그려져야겠죠

#### cordinate value

이사람의 관점에서 보면 ~ : 이사람의 좌표계ㅔ에서 보겠다
헐..신기하다
교수님 돆똑하다

#### model VIew Matrix

모델들이 어떻게 떨어져있는지 알려준다?

- model matrix : 모델 위치? 에 관한 행렬

  - scale, rotation, scale에 대한 조합
    > world의 관점에서 물어보면, model의 이동 matrix에 따라 위치를 대답할 것
  - 그런데 object한테 물어보면 얘는 좌표 0에 있다고 하겠죠
    local이랑 world 좌표계같네요

- view matrix: 카메라에 대한 행렬
  ㅇㅎ 역행렬 쓰는 이유 이해완
  그래서 사실 world는 그냥 계산하려고 있는거지 필요없음

기준을 카메라로 잡기 때문에 역행렬이 나온 거겠네요
그래서 여기까지 카메라 위치에 따라 모델의 위치계산하기 입니다

# 0407

### HIDDEN SURFACE REMOVAL

- Z BUFFER
  뭐...뭐요? A그리고 B그리냐 이런 거 상관없이 다 그리고 Z BUFFERㅇ ㅔ따라 결정

- PAINTER'S ALGORITHM
  렌더링 순서를 결정하고: 카메라 기준으로 가깝다 멀다를 알아내야함
  개체가 돌아다닐 때마다 .계싼해야함
  정렬 기준도 애매하고
- 물체 3개가 서로 꼬리의 꼬리를 물고 얽혀있으면 어떻게 그릴거냐
- z buffer을 활용할수 없을 때가 존재하기 땜에 사용 - 덮어씌울때...재질 - 투명한 것도 있고 그렇잖아 : 그럼 덮어 씌우는 방법(z buffer)을사용할 수 없을 수가 있음
  레이어 번호가 큰거부터 그리고 - 이후 작은 거 그리고 -
  ㅋㅋㅋ 일러스트도 그런 거 못그려서 킹받아요
  걍 ㄹㅇ 이름 말그대로 그림그리는 새끼들이 이해하는 방식인거구만

- BACKFACE REMOVAL (CULLING?)
  반시계 방향으로 정보를 주기로 약속함 - 등에있는 건 시계방향으로 정보를 주는 걸로 보이겠죠 (근데 이걸 컴터가 어케알음?)
  아 normal에서 말하는 면의 방향이 이거를 말하는 거구나? normal vector 이 정보를 넘겨주는 방향인거구나?

기하와 벡터 배우셨죠? 하셨는데 ㅇㅅㅇ하고있으니까 교수님이 자자자 코드로 설명해주께 이럼

물체의 좌표계에서 벡터 계산 가능하죠? 이 벡터 world 좌표계로 옮겨야겠죠? 그럴라면 world 의 matrix곱해야겠죠?
허허~ 이러고 내접? 뭐? 그거 90도면 0 나오고 그거? 뭔지는 모르겠는데요?

교수님 그...그만..

# 0414

viewport는 굳이 지정하지 않아도 곱해진대
그럼 애초부터 vertex processor 말고 fragment processor에서 색깔 이랑 재질 계산하면 될 것을 왜 70년대엔 vertex processor에서 색 계산을 했을까?

계산은 바르고 메모리는 적게 쓰는 게 목적인데 처음부터 이렇게 할 수가 없음(픽셀마다 색 계산을 할 수가 없었음, 정점마다 계산했음 )

varying. 이름 같게하면 vertex processor 에서는 vertex, fragment shader에서는 fragment로 계산함
그럼 처음엔 varying이 3개여겠지만 fragment로 가면 293개가 되겠죠

### gl_Position, gl_FragColor

assign 안했는데 쓰고 있음. 뭘까요? : 초기에 예약이 되어있다는데 뭐...뭐요?

전에 ertex array...이란 코드 ㅆ ㅡㄹ 때 채워준 함수임
glEnavleVertexAttribArray 기억나죠?

gpu한테 shader 코드를 줄건데 그 프로그램안에 a_position이라는 변수를 썻느데 그 위치를 알 수 있는 힌트를 int로 알려줘 :` Glint loc_a_position = glGetAttribLocation`

그래서 cpu 단에서 이미 assign 된거고, (a_position, a_color) 이거를 gpu에 보낸? 겅미

gpu에 올라가는것도 코드라서 컴파일하고 뭐하고 개질알을 해야되
그래서 얘네 컴파일하면 vertex shader object coode, 즉 기계어가 나옴 근데이게 fragment object code 이것도 따로 있고... 얘네를 연결 해줄 수 있어야함 ( shader program)

openGL은 얘의 내부 코드로 다 처리함

### 근데 그럼 CPU는 모든 데이터를 GPU에 다 넣을 수 있나?

아뇨 PPT상의 녹색부분... attribute만 넣어줄수 있어여
그리고 gpu의 글로벌 값? 전역속성이랑 texture 만 넣어줄 수 있어요
cpu에서 gpu
shader 입장에서 uniform은 읽을 수 만 있음, cpu가 채웢줌
vertex shader도 마찬가지

vertex shader 에선 varying 을 편집할 수 있음 근데 fragment에서 assgin은... 읽기만 할 수 있음

### output

vertex: varying 을 내놓던지 예약어를 내어놓든지

# 0507

-- 에서 들어온 빛이 --로 나가는 값을 모든 지점에서 계산하는거
실시간 포기, vrdf? 를 어떻게 가짜를 진짜처럼 만들까?

### phong reflection

주변광을 그냥 대충 결정하자. 이 복잡한거 복잡하게 계산하지 말자
주변광 세팅하는법!! ㅈㄴ 간단한 로직을 만든거예요
빛과 재질의 상호작용이니까앰비언트만을 관장하는 빛이 있을 거임 - 이게 L, 그리고 이 앰비언트 라이트에만 관장하는 계수가 있을거임 이게 k

- 난반사: 모든 방향으로 빛이 튕겨나갈거다. 이게 difuse reflection
  이거를 통해서 빛이 강하게 쬐ㅕ지면 강하게... 약하게 쬐여지지면 약하게 계산
  빛을 직접받았느냐 접선처럼 받았느냐 이걸로 계싼

- 정반사광 -정반사입니다. 정반사대비 튕겨나가는 반사의 각도가 들어오는 갇고랑 같음 ㅜ
  반사 방향과 ㅏ메라의 방향이 얼마나 일치하느냐에 따라...

# 0519

텍스쳐를 하고 있었음
점에 대해서 텍스쳐의 위치를 정하는 거니까 이거도 버텍스 애트리뷰트가 되겠죠
그래서 버텍스마다 텍스트 좌표값이라는 게 있을 텐데 ~
이 좌표값에 대한 문제 - 1을 넘어가거나 0보다 작으면 어떻게 할까

1. 1보다 작으면 그냥 1, 0보다 작으면 0으로 매핑
2. 반복

### Sampling problem - Aliasing

모델링의 한 픽셀이 텍스쳐이미지의 여러픽셀에 걸쳐있을 때 어떻게 해결할까?

원인:limited sampling rates
소위 말하는 계단현상인것같네요
자동차가 앞으로 가는 걸 비디오 영상으로 찍었을 때 자동차 바퀴가 뒤로가는 거처럼 보이는 경우

### anti aliasing

primitive color \* occupied rate 해서 흐릿하게 그려지게 함

### 확대 / 축소

텍스쳐의 한 픽셀이 스크린의 여러 픽셀에 있는 경우 / 그 반대의 경우
축소된 경우 - 한 픽셀 안에 여러 픽셀이 여러번 들어와서, 줄무늬가 축소될 경우, 다른 무늬가 생길 수도 있음

### minification 해결

1. nearest sampling : 뭐라하셨지
2. linear sampling: 각 색깔에 얼마나 가까우느냐 하는식으로 합쳐질 색상 선택해서 축소함
3. mipmap : 미리 여러 해상도의 이미지 만들어서 저장해놓음
   그러고 멀리있으면 작은거불러오고 가까이있으면 큰거 불러오고
   메모리를 더써서 계산을 더해놓는 거죠

# 0526

alpha blending
을... 지난 주에 한듯 하네요

## texture mapping

1. 버퍼만들기
2. 묶기
3. 텍스쳐 모드 결정
4. 텍스쳐 이미지 불러오기

메인메모리 >> gpu 메모리로 카피할때
메인메모리에서 ram copy를 하면 메모리를그대로 붙일 수 있는데
포맷이 다르면 각 픽셀마다 변환해야함 : 이건 속도가 엄청 느림

그래서! 하드디스크에서 메인 메모리로 옮길 때
이미지가 비트맵 데이터 형태로 저장되어있어야한다

메인 메모리로 옮기만 GLint, GLsize 같은 거

### mipmap

genMipmap 하면 됨

### texture blending

텍스쳐 2개를 합쳐서 1개로 만드는거

1 texture stage , 2 texture stage

base map

# 0528

openGl으ㅣ 역사를 개괄해주심
음...

rendering synthetic objects into Real scenes

dynamic range / 가끔 핸드폰에 뜨는 HDR이 밝기값? 그런거였음
오 빛의 노출 정도를 다양화한 거래

multiple render target: 파이프라인은 하나인데 결과물? 여러개 렌더?
첫번쨰 화면에는 디퓨즈 그리고 두번째엔 노말 그리고 뭐 그런식...
이걸 다합치는 걸라나? - deferred
각각의 도화지에 렌더를 위한 자료를 렌더링 하고 마지막 도화지에 이걸 다합쳐서 그림

왜 이렇게 따려 그리는 걸까요?
